---
title: Day 6 of 50daysofkaggle
author: ''
date: '2022-10-12'
slug: day-6-of-50daysofkaggle
categories:
  - kaggle
tags:
  - 50daysofkaggle
  - kaggle
  - machinelearning
  - python
subtitle: ''
summary: ''
authors: []
lastmod: '2022-10-12T15:38:17+05:30'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

# Day 6: The Titanic Dataset

Progress till date:

-   Download titanic dataset and assign to `train` & `test`
-   Rearranging the data
-   EDA

To do today:

-   write function to find share of survivors by each variable
-   attempt to create model

```{python}
import requests
import numpy as np
import pandas as pd
import kaggle 
import zipfile 

kaggle.api.authenticate()

kaggle.api.competition_download_files("titanic", path = ".")

zf = zipfile.ZipFile("titanic.zip")
train = pd.read_csv(zf.open("train.csv"))
test = pd.read_csv(zf.open("test.csv"))

#Selecting only the numerical columns
num_col = train.select_dtypes(include=np.number).columns.tolist()

#deslecting passenger ID and 'Survived' 
del num_col[0:2] #.remove() can remove only 1 item. so for more than 1, use for loop 
select_col = num_col

#remaining columns
str_col= ["Sex", "Embarked", "Survived"]
str_col

#Adding more elements into a list using `extend` and not `append`
select_col.extend(str_col)
select_col

train_eda= train[train.columns.intersection(select_col)]
train_eda

```

Today I want to calculate the survival rate of each of these attributes (`Pclass, Sex, Embarked`).

```{python}

df_copy2 = pd.DataFrame(columns = {"category", "col", "survive_rate"})

for t in ["Pclass", "Sex", "Embarked"]:
  df_copy = train_eda.groupby([t])["Survived"].mean().reset_index()
  df_copy["category"] = t
  #trying to create a `tidy` version of the data 
  df_copy.rename(columns = {t: "col", "Survived": "survive_rate"}, errors = "raise", inplace = True)
  df_copy = df_copy[["category", "col", "survive_rate"]]
  df_copy2= pd.concat([df_copy2, df_copy], ignore_index = True)


#final table in a tidy format that can be used to create graphs. but that i'm keeping for later
df_copy2[["category", "col", "survive_rate"]]
```

With this, its pretty clear that among the `sex` category, males had the least likelihood of surviving with 19%. The richer `class 1` managed a 63% chance of survival while only 24% of the lower `class 3` survived. Finally those that `embarked` from Cherbourg had a higher survival rate 55% compared to Southampton at 34%.

*ignore below. the following code should NOT be seen*

```{python ignore, eval=FALSE, include=FALSE}


```

## Model building

Seperating the X & y

```{python}


train_eda = train_eda.dropna(axis = 0) #removing all rows with NA

X = train_eda[["Age", "SibSp", "Parch", "Fare"]]
X


X = pd.concat([X,pd.get_dummies(data = train_eda[["Sex", "Embarked", "Pclass"]], columns = ["Sex", "Embarked", "Pclass"])], axis = 1)

X.head()

y = train_eda["Survived"].values
y[0:5]

len(y) #712
X.shape #(712, 12)
```

### Normalising the data

```{python}
X= preprocessing.StandardScaler().fit(X).transform(X)
X[0:5]
```

### Splitting into Test & Train data

```{python}
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print ('Train set\t :', X_train.shape,  y_train.shape,
'\nTest set\t :', X_test.shape,  y_test.shape)


```

### Standardising the values

```{python}
from sklearn import preprocessing

X= preprocessing.StandardScaler().fit(X).transform(X)

X[0:5]
```

Ignore everything below this

```{python}
test.info()


```
