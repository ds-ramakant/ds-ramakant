---
title: "Day 6 of 50daysofkaggle"
author: ''
date: "2022-10-12"
slug: "day-6-of-50daysofkaggle"
categories: kaggle
tags:
- 50daysofkaggle
- kaggle
- machinelearning
- python
subtitle: Classification using KNN
summary: ''
authors: []
lastmod: "2022-10-12T15:38:17+05:30"
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="day-6-the-titanic-dataset" class="section level1">
<h1>Day 6: The Titanic Dataset</h1>
<p>Progress till date:</p>
<ul>
<li>Download titanic dataset and assign to <code>train</code> &amp; <code>test</code></li>
<li>Rearranging the data</li>
<li>EDA</li>
</ul>
<p>To do today:</p>
<ul>
<li>write function to find share of survivors by each variable</li>
<li>attempt to create model</li>
</ul>
<pre class="python"><code>import requests
import numpy as np
import pandas as pd
import kaggle 
import zipfile 

kaggle.api.authenticate()

kaggle.api.competition_download_files(&quot;titanic&quot;, path = &quot;.&quot;)

zf = zipfile.ZipFile(&quot;titanic.zip&quot;)
train = pd.read_csv(zf.open(&quot;train.csv&quot;))
test = pd.read_csv(zf.open(&quot;test.csv&quot;))

#Selecting only the numerical columns
num_col = train.select_dtypes(include=np.number).columns.tolist()

#deslecting passenger ID and &#39;Survived&#39; 
del num_col[0:2] #.remove() can remove only 1 item. so for more than 1, use for loop 
select_col = num_col

#remaining columns
str_col= [&quot;Sex&quot;, &quot;Embarked&quot;, &quot;Survived&quot;]
str_col

#Adding more elements into a list using `extend` and not `append`</code></pre>
<pre><code>## [&#39;Sex&#39;, &#39;Embarked&#39;, &#39;Survived&#39;]</code></pre>
<pre class="python"><code>select_col.extend(str_col)
select_col</code></pre>
<pre><code>## [&#39;Pclass&#39;, &#39;Age&#39;, &#39;SibSp&#39;, &#39;Parch&#39;, &#39;Fare&#39;, &#39;Sex&#39;, &#39;Embarked&#39;, &#39;Survived&#39;]</code></pre>
<pre class="python"><code>train_eda= train[train.columns.intersection(select_col)]
train_eda</code></pre>
<pre><code>##      Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked
## 0           0       3    male  22.0      1      0   7.2500        S
## 1           1       1  female  38.0      1      0  71.2833        C
## 2           1       3  female  26.0      0      0   7.9250        S
## 3           1       1  female  35.0      1      0  53.1000        S
## 4           0       3    male  35.0      0      0   8.0500        S
## ..        ...     ...     ...   ...    ...    ...      ...      ...
## 886         0       2    male  27.0      0      0  13.0000        S
## 887         1       1  female  19.0      0      0  30.0000        S
## 888         0       3  female   NaN      1      2  23.4500        S
## 889         1       1    male  26.0      0      0  30.0000        C
## 890         0       3    male  32.0      0      0   7.7500        Q
## 
## [891 rows x 8 columns]</code></pre>
<pre class="python"><code>train_eda.isna().sum().sort_values()</code></pre>
<pre><code>## Survived      0
## Pclass        0
## Sex           0
## SibSp         0
## Parch         0
## Fare          0
## Embarked      2
## Age         177
## dtype: int64</code></pre>
<p>Almost 177 entries in the <code>Age</code> column have no value. Replacing these with the median age instead of removing them.</p>
<pre class="python"><code>
train_eda[&quot;Age&quot;].median() #28</code></pre>
<pre><code>## 28.0</code></pre>
<pre class="python"><code>train_eda[&quot;Age&quot;].fillna(value = train_eda[&quot;Age&quot;].median(), inplace = True)</code></pre>
<pre><code>## &lt;string&gt;:1: SettingWithCopyWarning: 
## A value is trying to be set on a copy of a slice from a DataFrame
## 
## See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy</code></pre>
<pre class="python"><code>train_eda.isna().sum().sort_values()</code></pre>
<pre><code>## Survived    0
## Pclass      0
## Sex         0
## Age         0
## SibSp       0
## Parch       0
## Fare        0
## Embarked    2
## dtype: int64</code></pre>
<p>Today I want to calculate the survival rate of each of these attributes (<code>Pclass, Sex, Embarked</code>).</p>
<pre class="python"><code>
df_copy2 = pd.DataFrame(columns = {&quot;category&quot;, &quot;col&quot;, &quot;survive_rate&quot;})

for t in [&quot;Pclass&quot;, &quot;Sex&quot;, &quot;Embarked&quot;]:
  df_copy = train_eda.groupby([t])[&quot;Survived&quot;].mean().reset_index()
  df_copy[&quot;category&quot;] = t
  #trying to create a `tidy` version of the data 
  df_copy.rename(columns = {t: &quot;col&quot;, &quot;Survived&quot;: &quot;survive_rate&quot;}, errors = &quot;raise&quot;, inplace = True)
  df_copy = df_copy[[&quot;category&quot;, &quot;col&quot;, &quot;survive_rate&quot;]]
  df_copy2= pd.concat([df_copy2, df_copy], ignore_index = True)


#final table in a tidy format that can be used to create graphs. but that i&#39;m keeping for later
df_copy2[[&quot;category&quot;, &quot;col&quot;, &quot;survive_rate&quot;]]</code></pre>
<pre><code>##    category     col survive_rate
## 0    Pclass       1      0.62963
## 1    Pclass       2     0.472826
## 2    Pclass       3     0.242363
## 3       Sex  female     0.742038
## 4       Sex    male     0.188908
## 5  Embarked       C     0.553571
## 6  Embarked       Q      0.38961
## 7  Embarked       S     0.336957</code></pre>
<p>With this, its pretty clear that among the <code>sex</code> category, males had the least likelihood of surviving with 19%. The richer <code>class 1</code> managed a 63% chance of survival while only 24% of the lower <code>class 3</code> survived. Finally those that <code>embarked</code> from Cherbourg had a higher survival rate 55% compared to Southampton at 34%.</p>
<div id="model-building" class="section level2">
<h2>Model building</h2>
<p>Seperating the X &amp; y</p>
<pre class="python"><code>
train_eda.isna().sum().sort_values()
</code></pre>
<pre><code>## Survived    0
## Pclass      0
## Sex         0
## Age         0
## SibSp       0
## Parch       0
## Fare        0
## Embarked    2
## dtype: int64</code></pre>
<pre class="python"><code>train_eda = train_eda.dropna(axis = 0) #removing all rows with NA

X = train_eda[[&quot;Age&quot;, &quot;SibSp&quot;, &quot;Parch&quot;, &quot;Fare&quot;]]
X
</code></pre>
<pre><code>##       Age  SibSp  Parch     Fare
## 0    22.0      1      0   7.2500
## 1    38.0      1      0  71.2833
## 2    26.0      0      0   7.9250
## 3    35.0      1      0  53.1000
## 4    35.0      0      0   8.0500
## ..    ...    ...    ...      ...
## 886  27.0      0      0  13.0000
## 887  19.0      0      0  30.0000
## 888  28.0      1      2  23.4500
## 889  26.0      0      0  30.0000
## 890  32.0      0      0   7.7500
## 
## [889 rows x 4 columns]</code></pre>
<pre class="python"><code>X = pd.concat([X,pd.get_dummies(data = train_eda[[&quot;Sex&quot;, &quot;Embarked&quot;, &quot;Pclass&quot;]], columns = [&quot;Sex&quot;, &quot;Embarked&quot;, &quot;Pclass&quot;])], axis = 1)

X.head()</code></pre>
<pre><code>##     Age  SibSp  Parch     Fare  ...  Embarked_S  Pclass_1  Pclass_2  Pclass_3
## 0  22.0      1      0   7.2500  ...           1         0         0         1
## 1  38.0      1      0  71.2833  ...           0         1         0         0
## 2  26.0      0      0   7.9250  ...           1         0         0         1
## 3  35.0      1      0  53.1000  ...           1         1         0         0
## 4  35.0      0      0   8.0500  ...           1         0         0         1
## 
## [5 rows x 12 columns]</code></pre>
<pre class="python"><code>y = train_eda[&quot;Survived&quot;].values
y[0:5]</code></pre>
<pre><code>## array([0, 1, 1, 1, 0], dtype=int64)</code></pre>
<pre class="python"><code>len(y) #889 after filling up the NA. previously 712</code></pre>
<pre><code>## 889</code></pre>
<pre class="python"><code>X.shape #(889, 12)</code></pre>
<pre><code>## (889, 12)</code></pre>
<div id="normalising-the-data" class="section level3">
<h3>Normalising the data</h3>
<pre class="python"><code>from sklearn import preprocessing

X= preprocessing.StandardScaler().fit(X).transform(X)
X[0:5]</code></pre>
<pre><code>## array([[-0.56367407,  0.43135024, -0.47432585, -0.50023975, -0.73534203,
##          0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,
##         -0.51087465,  0.90032807],
##        [ 0.66921696,  0.43135024, -0.47432585,  0.78894661,  1.35991138,
##         -1.35991138,  2.07163382, -0.30794088, -1.62128697,  1.77600834,
##         -0.51087465, -1.11070624],
##        [-0.25545131, -0.47519908, -0.47432585, -0.48664993,  1.35991138,
##         -1.35991138, -0.48271079, -0.30794088,  0.61679395, -0.56306042,
##         -0.51087465,  0.90032807],
##        [ 0.43804989,  0.43135024, -0.47432585,  0.42286111,  1.35991138,
##         -1.35991138, -0.48271079, -0.30794088,  0.61679395,  1.77600834,
##         -0.51087465, -1.11070624],
##        [ 0.43804989, -0.47519908, -0.47432585, -0.4841333 , -0.73534203,
##          0.73534203, -0.48271079, -0.30794088,  0.61679395, -0.56306042,
##         -0.51087465,  0.90032807]])</code></pre>
</div>
<div id="splitting-into-test-train-data" class="section level3">
<h3>Splitting into Test &amp; Train data</h3>
<pre class="python"><code>
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)
print (&#39;Train set\t :&#39;, X_train.shape,  y_train.shape,
&#39;\nTest set\t :&#39;, X_test.shape,  y_test.shape)
</code></pre>
<pre><code>## Train set     : (711, 12) (711,) 
## Test set  : (178, 12) (178,)</code></pre>
</div>
<div id="k-nearest-neighbours" class="section level3">
<h3>K Nearest Neighbours</h3>
<pre class="python"><code>
from sklearn.neighbors import KNeighborsClassifier

k = 4

neighbours = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)
neighbours</code></pre>
<pre><code>## KNeighborsClassifier(n_neighbors=4)</code></pre>
<div id="predicting-the-output-yhat-and-checking-accuracy" class="section level4">
<h4>Predicting the output <code>yhat</code> and checking accuracy</h4>
<pre class="python"><code>
yhat1 = neighbours.predict(X_test)
yhat1[0:5]</code></pre>
<pre><code>## array([0, 1, 0, 0, 1], dtype=int64)</code></pre>
<pre class="python"><code>from sklearn import metrics

print(&quot;Train set Accuracy \t:&quot;, metrics.accuracy_score(y_train, neighbours.predict(X_train)), &quot;\nTest set Accuracy \t:&quot;, metrics.accuracy_score(y_test, yhat1))</code></pre>
<pre><code>## Train set Accuracy   : 0.8509142053445851 
## Test set Accuracy    : 0.7584269662921348</code></pre>
<p><em>(without replacing <code>na</code> values, the previous test accuracy was 78%)</em>
#### Checking for other K</p>
<pre class="python"><code>from sklearn import metrics

Ks = 10
mean_acc = np.zeros((Ks-1))
std_acc = np.zeros((Ks-1))

for n in range(1,Ks):
    #Train Model and Predict  
    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)
    yhat=neigh.predict(X_test)
    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)
    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])

mean_acc</code></pre>
<pre><code>## array([0.78651685, 0.76404494, 0.7752809 , 0.75842697, 0.78089888,
##        0.78651685, 0.80337079, 0.7752809 , 0.78089888])</code></pre>
<p>By now youâ€™d have figured that all this is pretty much copy-pasta from someplace else. Glad that IBM coursera assignments came in handy!</p>
<pre class="python"><code>import matplotlib.pyplot as plt

plt.plot(range(1,Ks),mean_acc,&#39;g&#39;)
plt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)
plt.fill_between(range(1,Ks),mean_acc - 3 * std_acc,mean_acc + 3 * std_acc, alpha=0.10,color=&quot;green&quot;)
plt.legend((&#39;Accuracy &#39;, &#39;+/- 1xstd&#39;,&#39;+/- 3xstd&#39;))
plt.ylabel(&#39;Accuracy &#39;)
plt.xlabel(&#39;Number of Neighbors (K)&#39;)
plt.tight_layout()
plt.show()</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Looks like accuracy of KNN is best at 7 neighbours.
<em>previously without replacing NA the accuracy was highest at k = 5</em></p>
</div>
<div id="redo-with-k-5" class="section level4">
<h4>Redo with <code>K = 5</code></h4>
<pre class="python"><code>k = 7

neighbours_7 = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)
yhat = neighbours_7.predict(X_test)

print(&quot;Train set Accuracy \t:&quot;, 
      metrics.accuracy_score(y_train, neighbours_7.predict(X_train)),
      &quot;\nTest set Accuracy \t:&quot;, 
      metrics.accuracy_score(y_test, yhat))</code></pre>
<pre><code>## Train set Accuracy   : 0.8509142053445851 
## Test set Accuracy    : 0.8033707865168539</code></pre>
<p>We find that Test accuracy is around <strong>80% for KNN</strong>
<em>pretty much the same as previous attempt before replacing NA</em></p>
</div>
</div>
</div>
</div>
